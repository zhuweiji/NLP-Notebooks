{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the use of spaCy in NLP, general and aspect-based sentiment analysis  \n",
    "\n",
    "#### Includes data collection, cleaning, and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Note: for the ease of reading and follow up by non NLP practicioners, NLP/ SA/ spaCy specific terminology will be tagged with [word] where needed</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third-party package imports\n",
    "<b>Spacy</b> is used to provide all relevant NLP procedures, including several trained models, built-in tokenization, annotations, etc\n",
    "\n",
    "<b>Beautiful Soup 4</b> provides web scraping functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup as bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load english small/medium model - models must be installed seperately from the base spacy package\n",
    "# python -m spacy download en_core_web_sm --user\n",
    "\n",
    "nlp = spacy.load(r'C:\\Users\\zhuwe\\AppData\\Roaming\\Python\\Python310\\site-packages\\en_core_web_sm\\en_core_web_sm-3.3.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape web data from sample news article\n",
    "link = \"https://www.channelnewsasia.com/singapore/hiv-risk-transmission-man-did-not-inform-sexual-partner-jail-2732376\"\n",
    "\n",
    "resp = requests.get(link)\n",
    "assert resp.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only text in the <p> tags \n",
    "news_text = [i.getText() for i in bs(resp.content).find_all('p')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually filter news website boilerplate, legal disclaimers, etc.\n",
    "non_boilerplate_text = news_text[3:-5]\n",
    "\n",
    "# create spacy DOC object\n",
    "doc = nlp(''.join(non_boilerplate_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of textual data in this article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in this news article: 27\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sentences in this news article: \" + str(len(list(doc.sents))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token-wise analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS (Part of Speech) tagging\n",
    "Using [POS] tags, we can determine if an individual [token] is a noun, adjective, etc.\n",
    "\n",
    "Skimming through available UPOS tags, the following seem to be most important for Sentiment Analysis\n",
    "| POS tag | full name | examples       |\n",
    "|---------|-----------|----------------|\n",
    "| adj     | adjective | enormous, fast |\n",
    "| adv     | adverb    | very, exactly  |\n",
    "| verb    | verb      | eat, running   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{sentenced,\n",
       " informing,\n",
       " named,\n",
       " diagnosed,\n",
       " interviewed,\n",
       " told,\n",
       " required,\n",
       " inform,\n",
       " perceived,\n",
       " pleaded,\n",
       " considered,\n",
       " offered,\n",
       " booked,\n",
       " decided,\n",
       " go,\n",
       " engaged,\n",
       " inform,\n",
       " contracting,\n",
       " obtain,\n",
       " accept,\n",
       " said,\n",
       " discovered,\n",
       " reported,\n",
       " claimed,\n",
       " assaulted,\n",
       " having,\n",
       " informing,\n",
       " contracting,\n",
       " charged,\n",
       " formed,\n",
       " taken,\n",
       " indicated,\n",
       " detected,\n",
       " indicated,\n",
       " stated,\n",
       " According,\n",
       " cited,\n",
       " was,\n",
       " detected,\n",
       " said,\n",
       " was,\n",
       " stated,\n",
       " tested,\n",
       " detected,\n",
       " taken,\n",
       " accepted,\n",
       " detected,\n",
       " stated,\n",
       " asked,\n",
       " noting,\n",
       " accused,\n",
       " means,\n",
       " was,\n",
       " inform,\n",
       " exposed,\n",
       " reoffended,\n",
       " said,\n",
       " accused,\n",
       " use,\n",
       " engaged,\n",
       " accept,\n",
       " mitigated,\n",
       " was,\n",
       " said,\n",
       " sought,\n",
       " arguing,\n",
       " transmit,\n",
       " consumed,\n",
       " including,\n",
       " clouded,\n",
       " added,\n",
       " disclose,\n",
       " knew,\n",
       " was,\n",
       " argued,\n",
       " \"Afraid,\n",
       " omitted,\n",
       " disclose,\n",
       " appealed,\n",
       " jailed,\n",
       " fined}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([token for token in doc if token.pos_ == 'VERB'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3089f27a91002a70eeb41efde26153e7688fdd37da48d75a7ca76c501d851ef9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
